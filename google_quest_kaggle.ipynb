{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_quest_kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "01QSAy4zCrtQ",
        "colab_type": "code",
        "outputId": "b5c74bf6-bd76-4340-a507-18a41fde3f1c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/input/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrmLMKBpGMgW",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"../input/google-quest-challenge/train.csv\")\n",
        "test = pd.read_csv(\"../input/google-quest-challenge/test.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB0X0wd4LxTf",
        "colab_type": "code",
        "outputId": "0c715e65-5006-4a56-ae62-64064fe48430",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "source": [
        "drop_data_temp=data.drop(['question_user_name', 'question_user_page','answer_user_name','answer_user_page','url','host'], axis=1)\n",
        "drop_data_temp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>answer</th>\n",
              "      <th>category</th>\n",
              "      <th>question_asker_intent_understanding</th>\n",
              "      <th>question_body_critical</th>\n",
              "      <th>question_conversational</th>\n",
              "      <th>question_expect_short_answer</th>\n",
              "      <th>question_fact_seeking</th>\n",
              "      <th>question_has_commonly_accepted_answer</th>\n",
              "      <th>question_interestingness_others</th>\n",
              "      <th>question_interestingness_self</th>\n",
              "      <th>question_multi_intent</th>\n",
              "      <th>question_not_really_a_question</th>\n",
              "      <th>question_opinion_seeking</th>\n",
              "      <th>question_type_choice</th>\n",
              "      <th>question_type_compare</th>\n",
              "      <th>question_type_consequence</th>\n",
              "      <th>question_type_definition</th>\n",
              "      <th>question_type_entity</th>\n",
              "      <th>question_type_instructions</th>\n",
              "      <th>question_type_procedure</th>\n",
              "      <th>question_type_reason_explanation</th>\n",
              "      <th>question_type_spelling</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ... answer_well_written\n",
              "0      0  ...            1.000000\n",
              "1      1  ...            0.888889\n",
              "2      2  ...            0.888889\n",
              "3      3  ...            1.000000\n",
              "4      5  ...            1.000000\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIT87MoP1uSd",
        "colab_type": "code",
        "outputId": "ff6043f1-1d66-4951-8756-03cf705fae59",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "\n",
        "drop_test=test.drop(['question_user_name', 'question_user_page','answer_user_name','answer_user_page','url','host','category'], axis=1)\n",
        "drop_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>Will leaving corpses lying around upset my pri...</td>\n",
              "      <td>I see questions/information online about how t...</td>\n",
              "      <td>There is no consequence for leaving corpses an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>Url link to feature image in the portfolio</td>\n",
              "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
              "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70</td>\n",
              "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
              "      <td>To experiment I started a bot game, toggled in...</td>\n",
              "      <td>You do not have armour in the screenshots. Thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>132</td>\n",
              "      <td>Suddenly got an I/O error from my external HDD</td>\n",
              "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
              "      <td>Your Western Digital hard drive is disappearin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200</td>\n",
              "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
              "      <td>I have bought Delhi-London return flights for ...</td>\n",
              "      <td>I called two persons who work for Saudia (tick...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_id  ...                                             answer\n",
              "0     39  ...  There is no consequence for leaving corpses an...\n",
              "1     46  ...  I think it is possible with custom fields.\\n\\n...\n",
              "2     70  ...  You do not have armour in the screenshots. Thi...\n",
              "3    132  ...  Your Western Digital hard drive is disappearin...\n",
              "4    200  ...  I called two persons who work for Saudia (tick...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSPRJ4yXPlhh",
        "colab_type": "code",
        "outputId": "32ca691a-f50f-4e25-9a25-14639d42420a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def text_cleaner(text):\n",
        "  rules = [\n",
        "      {r'>\\s+': u'>'},  # remove spaces after a tag opens or closes\n",
        "      {r'\\s+': u' '},  # replace consecutive spaces\n",
        "      {r'\\s*<br\\s*/?>\\s*': u'\\n'},  # newline after a <br>\n",
        "      {r'</(div)\\s*>\\s*': u'\\n'},  # newline after </p> and </div> and <h1/>...\n",
        "      {r'</(p|h\\d)\\s*>\\s*': u'\\n\\n'},  # newline after </p> and </div> and <h1/>...\n",
        "      {r'<head>.*<\\s*(/head|body)[^>]*>': u''},  # remove <head> to </head>\n",
        "      {r'<a\\s+href=\"([^\"]+)\"[^>]*>.*</a>': r'\\1'},  # show links instead of texts\n",
        "      {r'[ \\t]*<[^<]*?/?>': u''},  # remove remaining tags\n",
        "      {r'^\\s+': u''}  # remove spaces at the beginning\n",
        "  ]\n",
        "  for rule in rules:\n",
        "    for (k, v) in rule.items():\n",
        "        regex = re.compile(k)\n",
        "        text = regex.sub(v, text)\n",
        "    text = text.rstrip()\n",
        "  return text.lower()\n",
        "\n",
        "def preprocess_text(column):\n",
        "  ret_column=[]\n",
        "  i=0\n",
        "  max=0\n",
        "  for text in column:\n",
        "    i+=1\n",
        "    # result=text_cleaner(text)\n",
        "    result = re.sub(r'\\d+', '', text)\n",
        "    result = result.translate(str.maketrans('', '', string.punctuation))\n",
        "    result.strip()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(result)\n",
        "    result = [i for i in tokens if not i in stop_words]\n",
        "    lemmatizer=WordNetLemmatizer()\n",
        "    result=lemmatizer.lemmatize(' '.join(result))\n",
        "    ret_column.append(result)\n",
        "  return ret_column"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UYu2xvxUQEl",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "drop_data=drop_data_temp.copy()\n",
        "drop_data['question_title']=preprocess_text(drop_data['question_title'])\n",
        "drop_data['question_body']=preprocess_text(drop_data['question_body'])\n",
        "drop_data['answer']=preprocess_text(drop_data['answer'])\n",
        "\n",
        "drop_test['question_title']=preprocess_text(drop_test['question_title'])\n",
        "drop_test['question_body']=preprocess_text(drop_test['question_body'])\n",
        "drop_test['answer']=preprocess_text(drop_test['answer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdDBiGqpGkYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        " \n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        " \n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "    \n",
        "    # word index and corresponding tf-idf score\n",
        "    for idx, score in sorted_items:\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        " \n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results\n",
        "\n",
        "# you only needs to do this once, this is a mapping of index to\n",
        "def get_features(docs,top_words):\n",
        "  cv=CountVectorizer(max_df=0.85,stop_words=set(stopwords.words(\"english\")),max_features=10000)\n",
        "  word_count_vector=cv.fit_transform(docs)\n",
        "  tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "  tfidf_transformer.fit(word_count_vector)\n",
        "  feature_names=cv.get_feature_names()\n",
        "  tf_words=[]\n",
        "  for doc in docs:\n",
        "    #generate tf-idf for the given document\n",
        "    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,top_words)\n",
        "    tf_idf_values=[]\n",
        "    words=[]\n",
        "    tf_idf_values=[0 for x in range(top_words)]\n",
        "    cnt=0\n",
        "    for k in keywords:\n",
        "      words.append(k)\n",
        "      tf_idf_values[cnt]=keywords[k]\n",
        "      cnt+=1\n",
        "    tf_words.append([words,tf_idf_values])\n",
        "  return tf_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvH8hzfX_fMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qt=get_features(drop_data['question_title'],5)\n",
        "qb=get_features(drop_data['question_body'],20)\n",
        "a=get_features(drop_data['answer'],20)\n",
        "\n",
        "\n",
        "qt_te=get_features(drop_test['question_title'],5)\n",
        "qb_te=get_features(drop_test['question_body'],20)\n",
        "a_te=get_features(drop_test['answer'],20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WedFP5F3ljaz",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "  associated_cols=[[['question_title','question_body'],['question_asker_intent_understanding']],\n",
        "                  [['question_body'],['question_body_critical']],\n",
        "                  [['question_title','question_body'],['question_conversational']],\n",
        "                  [['question_title','question_body'],['question_interestingness_others']],\n",
        "                  [['question_title','question_body'],['question_interestingness_self']],\n",
        "                  [['question_title','question_body'],['question_multi_intent']],\n",
        "                  [['answer','question_title','question_body'],['question_not_really_a_question']],\n",
        "                  [['answer','question_title','question_body'],['question_opinion_seeking']],\n",
        "                  [['answer','question_title','question_body'],['question_fact_seeking']],\n",
        "                  [['question_title','question_body'],['question_well_written']],\n",
        "                  [['question_title','question_body'],['question_type_entity']],\n",
        "                  [['question_title','question_body'],['question_type_choice']],\n",
        "                  [['question_title','question_body'],['question_type_compare']],\n",
        "                  [['question_title','question_body'],['question_type_consequence']],\n",
        "                  [['question_title','question_body'],['question_type_definition']],\n",
        "                  [['question_title','question_body'],['question_type_instructions']],\n",
        "                  [['question_title','question_body'],['question_type_procedure']],\n",
        "                  [['answer','question_title','question_body'],['question_type_reason_explanation']],\n",
        "                  [['question_body'],['question_type_spelling']],\n",
        "                  # [['answer','both'],['answer_helpful']],\n",
        "                  # [['answer','both'],['answer_level_of_information']],\n",
        "                  # [['answer','both'],['answer_type_instructions']],\n",
        "                  # [['answer','both'],['answer_type_procedure']],\n",
        "                  # [['answer','both'],['answer_plausible']],\n",
        "                  # [['answer','both'],['answer_relevance']],\n",
        "                  # [['answer','both'],['answer_satisfaction']],\n",
        "                  # [['answer','both'],['answer_type_reason_explanation']],\n",
        "                  # [['answer','both'],['answer_well_written']],\n",
        "                  # [['answer','both'],['question_expect_short_answer']],\n",
        "                  # [['answer','both'],['question_has_commonly_accepted_answer']]],\n",
        "                  [['question_body','answer','both'],['answer_helpful']],\n",
        "                  [['question_body','answer','both'],['answer_level_of_information']],\n",
        "                  [['question_body','answer','both'],['answer_type_instructions']],\n",
        "                  [['question_body','answer','both'],['answer_type_procedure']],\n",
        "                  [['question_body','answer','both'],['answer_plausible']],\n",
        "                  [['question_body','answer','both'],['answer_relevance']],\n",
        "                  [['question_body','answer','both'],['answer_satisfaction']],\n",
        "                  [['question_body','answer','both'],['answer_type_reason_explanation']],\n",
        "                  [['answer'],['answer_well_written']],\n",
        "                  [['question_body','answer'],['question_expect_short_answer']],\n",
        "                  [['question_body','answer'],['question_has_commonly_accepted_answer']]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWW864Aow8SW",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.stats import binned_statistic\n",
        "\n",
        "def min_sparse(X):\n",
        "    if len(X.data) == 0:\n",
        "        return 0\n",
        "    m = X.data.min()\n",
        "    return m if X.getnnz() == X.size else min(m, 0)\n",
        "\n",
        "def max_sparse(m):\n",
        "    i = m.data.argmax()\n",
        "    return m.data[i]\n",
        "\n",
        "def pushZerosToEnd(arr): \n",
        "  count = 0 # Count of non-zero elements \n",
        "  ret_array=[]\n",
        "  for i in range(len(arr)): \n",
        "    if math.isnan(float(arr[i]))== False: \n",
        "        # here count is incremented \n",
        "        ret_array.append(arr[i]) \n",
        "    else:\n",
        "      count+=1\n",
        "  for i in range(count):\n",
        "    ret_array.append(0)\n",
        "\n",
        "def create_individual_features(arr,df):\n",
        "  new_feats=[]\n",
        "  for ind,elem in enumerate(arr):\n",
        "    print(ind)\n",
        "    total_words=len(df.iloc[ind].split(' '))\n",
        "    total_unique_words=len(set(df.iloc[ind].split(' ')))\n",
        "    if np.count_nonzero(elem[1])!=0:\n",
        "      average_tf=sum(elem[1]) / np.count_nonzero(elem[1])\n",
        "      min_=min(elem[1])\n",
        "      max_=max(elem[1])\n",
        "      twenty_fifth=stats.scoreatpercentile(np.array(elem[1]), 25)\n",
        "      fifty=stats.scoreatpercentile(np.array(elem[1]), 50)\n",
        "      seventy_five=stats.scoreatpercentile(np.array(elem[1]), 75)\n",
        "      var=np.array(elem[1]).var()\n",
        "      features=[total_words,total_unique_words,average_tf,min_,max_,twenty_fifth,fifty,seventy_five,var]\n",
        "      new_feats.append(features)\n",
        "    else:\n",
        "      new_feats.append([total_words,total_unique_words,0,0,0,0,0,0,0])\n",
        "  return new_feats\n",
        "\n",
        "def get_combined_features(q,a):\n",
        "  combined_features=[]\n",
        "  for ind,_ in enumerate(q):\n",
        "    que=q[ind]\n",
        "    ans=a[ind]\n",
        "    common_top_words=list(set(que[0]).intersection(ans[0]))\n",
        "    num_common=len(common_top_words)\n",
        "    if num_common!=0:\n",
        "      indexes_tf=[ans[0].index(x) for x in common_top_words]\n",
        "      indexes_tf=[ans[1][i] for i in indexes_tf]\n",
        "      average_tf=sum(indexes_tf) / np.count_nonzero(indexes_tf)\n",
        "      min_=min(indexes_tf)\n",
        "      max_=max(indexes_tf)\n",
        "      combined_features.append([num_common,average_tf,min_,max_])\n",
        "    else:\n",
        "      combined_features.append([0,0,0,0])\n",
        "  return combined_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8fRa1kiaWRc",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "qt=get_features(drop_data['question_title'],5)\n",
        "qb=get_features(drop_data['question_body'],20)\n",
        "a=get_features(drop_data['answer'],20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyEPkMoRMA5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_qt=scaler.fit_transform(create_individual_features(qt,drop_data['question_title']))\n",
        "X_qb=scaler.fit_transform(create_individual_features(qb,drop_data['question_body']))\n",
        "X_a=scaler.fit_transform(create_individual_features(a,drop_data['answer']))\n",
        "X_b=scaler.fit_transform(get_combined_features(qb,a))\n",
        "\n",
        "X_qt_te=scaler.fit_transform(create_individual_features(qt_te,drop_test['question_title']))\n",
        "X_qb_te=scaler.fit_transform(create_individual_features(qb_te,drop_test['question_body']))\n",
        "X_a_te=scaler.fit_transform(create_individual_features(a_te,drop_test['answer']))\n",
        "X_b_te=scaler.fit_transform(get_combined_features(qb_te,a_te))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGRYx2RO8JHE",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "features_dict_train={'question_title':X_qt,'question_body':X_qb,\"answer\":X_a,'both':X_b}\n",
        "features_dict_test={'question_title':X_qt_te,'question_body':X_qb_te,\"answer\":X_a_te,'both':X_b_te}\n",
        "submission=pd.DataFrame(columns=['qa_id','question_asker_intent_understanding','question_body_critical','question_conversational','question_expect_short_answer','question_fact_seeking','question_has_commonly_accepted_answer','question_interestingness_others','question_interestingness_self','question_multi_intent','question_not_really_a_question','question_opinion_seeking','question_type_choice','question_type_compare','question_type_consequence','question_type_definition','question_type_entity','question_type_instructions','question_type_procedure','question_type_reason_explanation','question_type_spelling','question_well_written','answer_helpful','answer_level_of_information','answer_plausible','answer_relevance','answer_satisfaction','answer_type_instructions','answer_type_procedure','answer_type_reason_explanation','answer_well_written'])\n",
        "submission['qa_id']=test['qa_id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyMGV3cPQHhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(labels,predictions):\n",
        "    \n",
        "    labels=np.array(labels)\n",
        "    predictions=np.array(predictions)\n",
        "    errors = abs(predictions - labels)\n",
        "    f = open(\"results.txt\", \"a\")\n",
        "    f.write(\"---------------------------------------------------\\n\")\n",
        "    f.write('Model Performance\\n')\n",
        "    f.write('Average Error: {:0.4f} degrees.\\n'.format(np.mean(errors)))\n",
        "    f.write(\"---------------------------------------------------\\n\")\n",
        "    f.close()\n",
        "    return np.mean(errors)\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "score = make_scorer(evaluate, greater_is_better=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC3gts2S0oUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from scipy import stats\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def my_model(model,associated_cols,param_grid,features_dict_train,features_dict_test):\n",
        "  scores=[]\n",
        "  returned_algorithm={}\n",
        "  for cases in associated_cols:\n",
        "    train_cols=[]\n",
        "    test_cols=[]\n",
        "    for col in cases[0]:\n",
        "      train_cols.append(features_dict_train[col])\n",
        "      test_cols.append(features_dict_test[col])\n",
        "    X_train= np.concatenate(train_cols, axis=1).tolist()\n",
        "    X_test= np.concatenate(test_cols, axis=1).tolist()\n",
        "    Y_train=drop_data[cases[1]]\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    xTrain,xTest, yTrain, yTest = train_test_split(X_train, Y_train,stratify=Y_train,test_size=0.80)\n",
        "    gs = GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',verbose=0)\n",
        "    start = time.time()\n",
        "    gs.fit(xTrain, yTrain)\n",
        "    end = time.time()\n",
        "    print(\"======================\",cases[1],\"=========================\")\n",
        "    print('Time to train model: %0.2fs' % (end -start))\n",
        "    # for i in ['mean_test_score', 'std_test_score']:\n",
        "    #     print(i,\" : \",gs.cv_results_[i].mean(),' with best parameters ',gs.best_params_)\n",
        "    score=stats.spearmanr(gs.predict(xTest),yTest)\n",
        "    scores.append(score.correlation)\n",
        "    print(\"Evaluation metric using spearman is \",score.correlation,)\n",
        "    print(\"Great for \",cases[1])\n",
        "    myModel=model\n",
        "    myModel.set_params(**gs.best_params_)\n",
        "    returned_algorithm[cases[1][0]]=[myModel,score.correlation, type(model).__name__]\n",
        "    print(\"======================================================================\")\n",
        "  print(\"Average score is \",sum(scores) / len(scores) )\n",
        "  return returned_algorithm\n",
        "\n",
        "def get_rem_columns(associated_cols):\n",
        "  for x in associated_cols:\n",
        "    if x[1][0] not in algorithms.keys():\n",
        "      new_associated_cols.append(x)\n",
        "    else:\n",
        "      print('Column ',x[1][0],\" finished.\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VVLvUXr1M7wK",
        "colab_type": "code",
        "outputId": "24ea30ed-37de-4097-b51f-898d2480f60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "all_algos=[]\n",
        "param_grid = {#'penalty':['none','l2','l1'],\n",
        "             'alpha':[0.01,0.1,1],\n",
        "             'max_iter':[10,100,1000,10000],\n",
        "             'early_stopping':[True]}\n",
        "sgd_algorithms=my_model(linear_model.SGDRegressor(),associated_cols,param_grid,features_dict_train,features_dict_test)\n",
        "all_algos.append(sgd_algorithms)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== ['question_asker_intent_understanding'] =========================\n",
            "Time to train model: 0.83s\n",
            "Evaluation metric using spearman is  0.10546907653595533\n",
            "Great for  ['question_asker_intent_understanding']\n",
            "======================================================================\n",
            "====================== ['question_body_critical'] =========================\n",
            "Time to train model: 0.52s\n",
            "Evaluation metric using spearman is  0.17096877922493925\n",
            "Great for  ['question_body_critical']\n",
            "======================================================================\n",
            "====================== ['question_conversational'] =========================\n",
            "Time to train model: 0.81s\n",
            "Evaluation metric using spearman is  0.09161778911706311\n",
            "Great for  ['question_conversational']\n",
            "======================================================================\n",
            "====================== ['question_interestingness_others'] =========================\n",
            "Time to train model: 1.04s\n",
            "Evaluation metric using spearman is  0.015754284192028394\n",
            "Great for  ['question_interestingness_others']\n",
            "======================================================================\n",
            "====================== ['question_interestingness_self'] =========================\n",
            "Time to train model: 0.92s\n",
            "Evaluation metric using spearman is  0.024727807798756413\n",
            "Great for  ['question_interestingness_self']\n",
            "======================================================================\n",
            "====================== ['question_multi_intent'] =========================\n",
            "Time to train model: 1.26s\n",
            "Evaluation metric using spearman is  0.07253261215278874\n",
            "Great for  ['question_multi_intent']\n",
            "======================================================================\n",
            "====================== ['question_not_really_a_question'] =========================\n",
            "Time to train model: 0.85s\n",
            "Evaluation metric using spearman is  -0.026271266296907524\n",
            "Great for  ['question_not_really_a_question']\n",
            "======================================================================\n",
            "====================== ['question_opinion_seeking'] =========================\n",
            "Time to train model: 0.96s\n",
            "Evaluation metric using spearman is  0.16124997857829365\n",
            "Great for  ['question_opinion_seeking']\n",
            "======================================================================\n",
            "====================== ['question_fact_seeking'] =========================\n",
            "Time to train model: 0.80s\n",
            "Evaluation metric using spearman is  0.11477910822681671\n",
            "Great for  ['question_fact_seeking']\n",
            "======================================================================\n",
            "====================== ['question_well_written'] =========================\n",
            "Time to train model: 0.83s\n",
            "Evaluation metric using spearman is  0.15323902455481964\n",
            "Great for  ['question_well_written']\n",
            "======================================================================\n",
            "====================== ['question_type_entity'] =========================\n",
            "Time to train model: 0.82s\n",
            "Evaluation metric using spearman is  0.03929716592502843\n",
            "Great for  ['question_type_entity']\n",
            "======================================================================\n",
            "====================== ['question_type_choice'] =========================\n",
            "Time to train model: 0.77s\n",
            "Evaluation metric using spearman is  0.050132621970453976\n",
            "Great for  ['question_type_choice']\n",
            "======================================================================\n",
            "====================== ['question_type_compare'] =========================\n",
            "Time to train model: 0.72s\n",
            "Evaluation metric using spearman is  0.04801669637985617\n",
            "Great for  ['question_type_compare']\n",
            "======================================================================\n",
            "====================== ['question_type_consequence'] =========================\n",
            "Time to train model: 0.71s\n",
            "Evaluation metric using spearman is  0.010713666930290048\n",
            "Great for  ['question_type_consequence']\n",
            "======================================================================\n",
            "====================== ['question_type_definition'] =========================\n",
            "Time to train model: 0.75s\n",
            "Evaluation metric using spearman is  0.10918223474375825\n",
            "Great for  ['question_type_definition']\n",
            "======================================================================\n",
            "====================== ['question_type_instructions'] =========================\n",
            "Time to train model: 0.79s\n",
            "Evaluation metric using spearman is  0.08725242014764198\n",
            "Great for  ['question_type_instructions']\n",
            "======================================================================\n",
            "====================== ['question_type_procedure'] =========================\n",
            "Time to train model: 0.97s\n",
            "Evaluation metric using spearman is  0.03470714044344969\n",
            "Great for  ['question_type_procedure']\n",
            "======================================================================\n",
            "====================== ['question_type_reason_explanation'] =========================\n",
            "Time to train model: 0.83s\n",
            "Evaluation metric using spearman is  0.08486179908961648\n",
            "Great for  ['question_type_reason_explanation']\n",
            "======================================================================\n",
            "====================== ['question_type_spelling'] =========================\n",
            "Time to train model: 0.48s\n",
            "Evaluation metric using spearman is  0.015546328680536159\n",
            "Great for  ['question_type_spelling']\n",
            "======================================================================\n",
            "====================== ['answer_helpful'] =========================\n",
            "Time to train model: 0.82s\n",
            "Evaluation metric using spearman is  0.03272893502577751\n",
            "Great for  ['answer_helpful']\n",
            "======================================================================\n",
            "====================== ['answer_level_of_information'] =========================\n",
            "Time to train model: 0.78s\n",
            "Evaluation metric using spearman is  0.12098653896579113\n",
            "Great for  ['answer_level_of_information']\n",
            "======================================================================\n",
            "====================== ['answer_type_instructions'] =========================\n",
            "Time to train model: 0.80s\n",
            "Evaluation metric using spearman is  0.15872257841688608\n",
            "Great for  ['answer_type_instructions']\n",
            "======================================================================\n",
            "====================== ['answer_type_procedure'] =========================\n",
            "Time to train model: 0.90s\n",
            "Evaluation metric using spearman is  0.07976072077887435\n",
            "Great for  ['answer_type_procedure']\n",
            "======================================================================\n",
            "====================== ['answer_plausible'] =========================\n",
            "Time to train model: 0.91s\n",
            "Evaluation metric using spearman is  0.02263157447994161\n",
            "Great for  ['answer_plausible']\n",
            "======================================================================\n",
            "====================== ['answer_relevance'] =========================\n",
            "Time to train model: 0.79s\n",
            "Evaluation metric using spearman is  0.013066288474274322\n",
            "Great for  ['answer_relevance']\n",
            "======================================================================\n",
            "====================== ['answer_satisfaction'] =========================\n",
            "Time to train model: 0.89s\n",
            "Evaluation metric using spearman is  0.0632501659205894\n",
            "Great for  ['answer_satisfaction']\n",
            "======================================================================\n",
            "====================== ['answer_type_reason_explanation'] =========================\n",
            "Time to train model: 0.78s\n",
            "Evaluation metric using spearman is  0.18397217998142343\n",
            "Great for  ['answer_type_reason_explanation']\n",
            "======================================================================\n",
            "====================== ['answer_well_written'] =========================\n",
            "Time to train model: 0.48s\n",
            "Evaluation metric using spearman is  0.0706833864209451\n",
            "Great for  ['answer_well_written']\n",
            "======================================================================\n",
            "====================== ['question_expect_short_answer'] =========================\n",
            "Time to train model: 0.83s\n",
            "Evaluation metric using spearman is  0.1786620499111735\n",
            "Great for  ['question_expect_short_answer']\n",
            "======================================================================\n",
            "====================== ['question_has_commonly_accepted_answer'] =========================\n",
            "Time to train model: 0.74s\n",
            "Evaluation metric using spearman is  0.17298751247213964\n",
            "Great for  ['question_has_commonly_accepted_answer']\n",
            "======================================================================\n",
            "Average score is  0.08204097330810006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IbXZHIgEqJV2",
        "colab_type": "code",
        "outputId": "fc88ed7c-8e51-445e-cdf6-f612379a8e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
        "gammas = [0.001, 0.01, 0.1, 1]\n",
        "param_grid = [\n",
        "  {'C': Cs,'gamma' : gammas, 'kernel': ['linear']},\n",
        "  {'C':Cs,'gamma' : gammas, 'kernel': ['rbf']}\n",
        "  ]\n",
        "svr_algorithms=my_model(SVR(),associated_cols,param_grid,features_dict_train,features_dict_test)\n",
        "all_algos.append(svr_algorithms)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== ['question_asker_intent_understanding'] =========================\n",
            "Time to train model: 22.20s\n",
            "Evaluation metric using spearman is  0.17820685056365027\n",
            "Great for  ['question_asker_intent_understanding']\n",
            "======================================================================\n",
            "====================== ['question_body_critical'] =========================\n",
            "Time to train model: 11.86s\n",
            "Evaluation metric using spearman is  0.2876567610059798\n",
            "Great for  ['question_body_critical']\n",
            "======================================================================\n",
            "====================== ['question_conversational'] =========================\n",
            "Time to train model: 7.48s\n",
            "Evaluation metric using spearman is  0.10825327499066056\n",
            "Great for  ['question_conversational']\n",
            "======================================================================\n",
            "====================== ['question_interestingness_others'] =========================\n",
            "Time to train model: 14.01s\n",
            "Evaluation metric using spearman is  0.15461782568116567\n",
            "Great for  ['question_interestingness_others']\n",
            "======================================================================\n",
            "====================== ['question_interestingness_self'] =========================\n",
            "Time to train model: 14.52s\n",
            "Evaluation metric using spearman is  0.16076054317418365\n",
            "Great for  ['question_interestingness_self']\n",
            "======================================================================\n",
            "====================== ['question_multi_intent'] =========================\n",
            "Time to train model: 20.21s\n",
            "Evaluation metric using spearman is  0.13505107897090443\n",
            "Great for  ['question_multi_intent']\n",
            "======================================================================\n",
            "====================== ['question_not_really_a_question'] =========================\n",
            "Time to train model: 4.01s\n",
            "Evaluation metric using spearman is  0.02123468530612179\n",
            "Great for  ['question_not_really_a_question']\n",
            "======================================================================\n",
            "====================== ['question_opinion_seeking'] =========================\n",
            "Time to train model: 19.17s\n",
            "Evaluation metric using spearman is  0.189370872956142\n",
            "Great for  ['question_opinion_seeking']\n",
            "======================================================================\n",
            "====================== ['question_fact_seeking'] =========================\n",
            "Time to train model: 29.58s\n",
            "Evaluation metric using spearman is  0.036918228458790975\n",
            "Great for  ['question_fact_seeking']\n",
            "======================================================================\n",
            "====================== ['question_well_written'] =========================\n",
            "Time to train model: 13.47s\n",
            "Evaluation metric using spearman is  0.3445606976176622\n",
            "Great for  ['question_well_written']\n",
            "======================================================================\n",
            "====================== ['question_type_entity'] =========================\n",
            "Time to train model: 7.62s\n",
            "Evaluation metric using spearman is  0.08624389831505283\n",
            "Great for  ['question_type_entity']\n",
            "======================================================================\n",
            "====================== ['question_type_choice'] =========================\n",
            "Time to train model: 17.59s\n",
            "Evaluation metric using spearman is  0.08957059477557026\n",
            "Great for  ['question_type_choice']\n",
            "======================================================================\n",
            "====================== ['question_type_compare'] =========================\n",
            "Time to train model: 5.39s\n",
            "Evaluation metric using spearman is  0.06327469009427895\n",
            "Great for  ['question_type_compare']\n",
            "======================================================================\n",
            "====================== ['question_type_consequence'] =========================\n",
            "Time to train model: 3.27s\n",
            "Evaluation metric using spearman is  0.007941041801283017\n",
            "Great for  ['question_type_consequence']\n",
            "======================================================================\n",
            "====================== ['question_type_definition'] =========================\n",
            "Time to train model: 5.54s\n",
            "Evaluation metric using spearman is  -0.0016897986463478931\n",
            "Great for  ['question_type_definition']\n",
            "======================================================================\n",
            "====================== ['question_type_instructions'] =========================\n",
            "Time to train model: 16.58s\n",
            "Evaluation metric using spearman is  0.23993571253830356\n",
            "Great for  ['question_type_instructions']\n",
            "======================================================================\n",
            "====================== ['question_type_procedure'] =========================\n",
            "Time to train model: 14.83s\n",
            "Evaluation metric using spearman is  0.030221081025114328\n",
            "Great for  ['question_type_procedure']\n",
            "======================================================================\n",
            "====================== ['question_type_reason_explanation'] =========================\n",
            "Time to train model: 19.19s\n",
            "Evaluation metric using spearman is  0.13477192803105212\n",
            "Great for  ['question_type_reason_explanation']\n",
            "======================================================================\n",
            "====================== ['question_type_spelling'] =========================\n",
            "Time to train model: 0.97s\n",
            "Evaluation metric using spearman is  -0.03938223577836317\n",
            "Great for  ['question_type_spelling']\n",
            "======================================================================\n",
            "====================== ['answer_helpful'] =========================\n",
            "Time to train model: 13.50s\n",
            "Evaluation metric using spearman is  0.07461607066924433\n",
            "Great for  ['answer_helpful']\n",
            "======================================================================\n",
            "====================== ['answer_level_of_information'] =========================\n",
            "Time to train model: 9.00s\n",
            "Evaluation metric using spearman is  0.3802725063012718\n",
            "Great for  ['answer_level_of_information']\n",
            "======================================================================\n",
            "====================== ['answer_type_instructions'] =========================\n",
            "Time to train model: 18.15s\n",
            "Evaluation metric using spearman is  0.18254089969486234\n",
            "Great for  ['answer_type_instructions']\n",
            "======================================================================\n",
            "====================== ['answer_type_procedure'] =========================\n",
            "Time to train model: 15.26s\n",
            "Evaluation metric using spearman is  0.030122659688250192\n",
            "Great for  ['answer_type_procedure']\n",
            "======================================================================\n",
            "====================== ['answer_plausible'] =========================\n",
            "Time to train model: 7.33s\n",
            "Evaluation metric using spearman is  0.012438776993520754\n",
            "Great for  ['answer_plausible']\n",
            "======================================================================\n",
            "====================== ['answer_relevance'] =========================\n",
            "Time to train model: 6.99s\n",
            "Evaluation metric using spearman is  0.01799172231458518\n",
            "Great for  ['answer_relevance']\n",
            "======================================================================\n",
            "====================== ['answer_satisfaction'] =========================\n",
            "Time to train model: 11.63s\n",
            "Evaluation metric using spearman is  0.22451322162639253\n",
            "Great for  ['answer_satisfaction']\n",
            "======================================================================\n",
            "====================== ['answer_type_reason_explanation'] =========================\n",
            "Time to train model: 17.83s\n",
            "Evaluation metric using spearman is  0.26307736902044987\n",
            "Great for  ['answer_type_reason_explanation']\n",
            "======================================================================\n",
            "====================== ['answer_well_written'] =========================\n",
            "Time to train model: 17.62s\n",
            "Evaluation metric using spearman is  0.04193182334664912\n",
            "Great for  ['answer_well_written']\n",
            "======================================================================\n",
            "====================== ['question_expect_short_answer'] =========================\n",
            "Time to train model: 17.75s\n",
            "Evaluation metric using spearman is  0.1963470173721226\n",
            "Great for  ['question_expect_short_answer']\n",
            "======================================================================\n",
            "====================== ['question_has_commonly_accepted_answer'] =========================\n",
            "Time to train model: 13.77s\n",
            "Evaluation metric using spearman is  0.16192955969342773\n",
            "Great for  ['question_has_commonly_accepted_answer']\n",
            "======================================================================\n",
            "Average score is  0.12710997858673276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mKSvV886UaM",
        "colab_type": "code",
        "outputId": "19e41972-f22d-4a34-9b9e-f0070a4e684b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [1,10,20,40]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [5,15,25,40]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "rfr_algorithms=my_model(RandomForestRegressor(),associated_cols,param_grid,features_dict_train,features_dict_test)\n",
        "all_algos.append(rfr_algorithms)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== ['question_asker_intent_understanding'] =========================\n",
            "Time to train model: 110.16s\n",
            "Evaluation metric using spearman is  0.14823071164352544\n",
            "Great for  ['question_asker_intent_understanding']\n",
            "======================================================================\n",
            "====================== ['question_body_critical'] =========================\n",
            "Time to train model: 66.25s\n",
            "Evaluation metric using spearman is  0.31535430555543964\n",
            "Great for  ['question_body_critical']\n",
            "======================================================================\n",
            "====================== ['question_conversational'] =========================\n",
            "Time to train model: 114.21s\n",
            "Evaluation metric using spearman is  0.173010261556178\n",
            "Great for  ['question_conversational']\n",
            "======================================================================\n",
            "====================== ['question_interestingness_others'] =========================\n",
            "Time to train model: 113.23s\n",
            "Evaluation metric using spearman is  0.14826173757458716\n",
            "Great for  ['question_interestingness_others']\n",
            "======================================================================\n",
            "====================== ['question_interestingness_self'] =========================\n",
            "Time to train model: 125.79s\n",
            "Evaluation metric using spearman is  0.17427760463013173\n",
            "Great for  ['question_interestingness_self']\n",
            "======================================================================\n",
            "====================== ['question_multi_intent'] =========================\n",
            "Time to train model: 114.26s\n",
            "Evaluation metric using spearman is  0.17097779252479164\n",
            "Great for  ['question_multi_intent']\n",
            "======================================================================\n",
            "====================== ['question_not_really_a_question'] =========================\n",
            "Time to train model: 100.00s\n",
            "Evaluation metric using spearman is  0.012917994435469803\n",
            "Great for  ['question_not_really_a_question']\n",
            "======================================================================\n",
            "====================== ['question_opinion_seeking'] =========================\n",
            "Time to train model: 182.84s\n",
            "Evaluation metric using spearman is  0.18202138246238767\n",
            "Great for  ['question_opinion_seeking']\n",
            "======================================================================\n",
            "====================== ['question_fact_seeking'] =========================\n",
            "Time to train model: 180.82s\n",
            "Evaluation metric using spearman is  0.13173204525984542\n",
            "Great for  ['question_fact_seeking']\n",
            "======================================================================\n",
            "====================== ['question_well_written'] =========================\n",
            "Time to train model: 106.57s\n",
            "Evaluation metric using spearman is  0.30802560387460043\n",
            "Great for  ['question_well_written']\n",
            "======================================================================\n",
            "====================== ['question_type_entity'] =========================\n",
            "Time to train model: 110.95s\n",
            "Evaluation metric using spearman is  0.13358891474377782\n",
            "Great for  ['question_type_entity']\n",
            "======================================================================\n",
            "====================== ['question_type_choice'] =========================\n",
            "Time to train model: 121.16s\n",
            "Evaluation metric using spearman is  0.17786389871744684\n",
            "Great for  ['question_type_choice']\n",
            "======================================================================\n",
            "====================== ['question_type_compare'] =========================\n",
            "Time to train model: 91.69s\n",
            "Evaluation metric using spearman is  0.0871175540397091\n",
            "Great for  ['question_type_compare']\n",
            "======================================================================\n",
            "====================== ['question_type_consequence'] =========================\n",
            "Time to train model: 88.83s\n",
            "Evaluation metric using spearman is  0.021428470284494176\n",
            "Great for  ['question_type_consequence']\n",
            "======================================================================\n",
            "====================== ['question_type_definition'] =========================\n",
            "Time to train model: 102.74s\n",
            "Evaluation metric using spearman is  0.14119664817129546\n",
            "Great for  ['question_type_definition']\n",
            "======================================================================\n",
            "====================== ['question_type_instructions'] =========================\n",
            "Time to train model: 104.78s\n",
            "Evaluation metric using spearman is  0.31749256892420674\n",
            "Great for  ['question_type_instructions']\n",
            "======================================================================\n",
            "====================== ['question_type_procedure'] =========================\n",
            "Time to train model: 109.18s\n",
            "Evaluation metric using spearman is  0.047936900377725765\n",
            "Great for  ['question_type_procedure']\n",
            "======================================================================\n",
            "====================== ['question_type_reason_explanation'] =========================\n",
            "Time to train model: 163.20s\n",
            "Evaluation metric using spearman is  0.19551050409860815\n",
            "Great for  ['question_type_reason_explanation']\n",
            "======================================================================\n",
            "====================== ['question_type_spelling'] =========================\n",
            "Time to train model: 21.61s\n",
            "Evaluation metric using spearman is  0.06125104976672804\n",
            "Great for  ['question_type_spelling']\n",
            "======================================================================\n",
            "====================== ['answer_helpful'] =========================\n",
            "Time to train model: 138.00s\n",
            "Evaluation metric using spearman is  0.09983617591381345\n",
            "Great for  ['answer_helpful']\n",
            "======================================================================\n",
            "====================== ['answer_level_of_information'] =========================\n",
            "Time to train model: 138.90s\n",
            "Evaluation metric using spearman is  0.3758768587392789\n",
            "Great for  ['answer_level_of_information']\n",
            "======================================================================\n",
            "====================== ['answer_type_instructions'] =========================\n",
            "Time to train model: 131.58s\n",
            "Evaluation metric using spearman is  0.2080850078070692\n",
            "Great for  ['answer_type_instructions']\n",
            "======================================================================\n",
            "====================== ['answer_type_procedure'] =========================\n",
            "Time to train model: 145.51s\n",
            "Evaluation metric using spearman is  0.056862505728408966\n",
            "Great for  ['answer_type_procedure']\n",
            "======================================================================\n",
            "====================== ['answer_plausible'] =========================\n",
            "Time to train model: 149.90s\n",
            "Evaluation metric using spearman is  0.02618071811387546\n",
            "Great for  ['answer_plausible']\n",
            "======================================================================\n",
            "====================== ['answer_relevance'] =========================\n",
            "Time to train model: 143.77s\n",
            "Evaluation metric using spearman is  0.0725086951122146\n",
            "Great for  ['answer_relevance']\n",
            "======================================================================\n",
            "====================== ['answer_satisfaction'] =========================\n",
            "Time to train model: 128.76s\n",
            "Evaluation metric using spearman is  0.1845509830963994\n",
            "Great for  ['answer_satisfaction']\n",
            "======================================================================\n",
            "====================== ['answer_type_reason_explanation'] =========================\n",
            "Time to train model: 129.77s\n",
            "Evaluation metric using spearman is  0.3210259598405564\n",
            "Great for  ['answer_type_reason_explanation']\n",
            "======================================================================\n",
            "====================== ['answer_well_written'] =========================\n",
            "Time to train model: 72.03s\n",
            "Evaluation metric using spearman is  0.06686742333398522\n",
            "Great for  ['answer_well_written']\n",
            "======================================================================\n",
            "====================== ['question_expect_short_answer'] =========================\n",
            "Time to train model: 118.23s\n",
            "Evaluation metric using spearman is  0.17791608464541817\n",
            "Great for  ['question_expect_short_answer']\n",
            "======================================================================\n",
            "====================== ['question_has_commonly_accepted_answer'] =========================\n",
            "Time to train model: 113.88s\n",
            "Evaluation metric using spearman is  0.2000839924871087\n",
            "Great for  ['question_has_commonly_accepted_answer']\n",
            "======================================================================\n",
            "Average score is  0.15793301178196925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ2Nu9NG-3sN",
        "colab_type": "code",
        "outputId": "a675f3b7-d39c-4cb0-b440-9cacbeab9ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "import pickle\n",
        "pkl_filename = \"/content/drive/My Drive/pickle_model.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(all_algos, file)\n",
        "for key in svr_algorithms.keys():\n",
        "  various_per_column=[]\n",
        "  X_train=[]\n",
        "  Y_train=[]\n",
        "  X_Test=[]\n",
        "  train_cols=[]\n",
        "  test_cols=[]\n",
        "  for elem in associated_cols:\n",
        "    if elem[1][0]==key:\n",
        "      for col in elem[0]:\n",
        "        train_cols.append(features_dict_train[col])\n",
        "        test_cols.append(features_dict_test[col])\n",
        "      X_train= np.concatenate(train_cols, axis=1).tolist()\n",
        "      X_test= np.concatenate(test_cols, axis=1).tolist()\n",
        "      Y_train=drop_data[key]\n",
        "  for algo in all_algos:\n",
        "    various_per_column.append(algo[key])\n",
        "  sorted_algo=sorted(various_per_column, key = lambda x: x[1])\n",
        "  myModel=sorted_algo[-1][0]\n",
        "  print('Best algorithm was ',sorted_algo[-1][2],' with training score ',sorted_algo[-1][1],' for ',key)\n",
        "  myModel.fit(X_train,Y_train)\n",
        "  predictions=[round(float(pred),5) for pred in myModel.predict(X_test)]\n",
        "  over_values=False\n",
        "  final_pred=[]\n",
        "  for elem in predictions:\n",
        "    if elem<0 or elem >1:\n",
        "      if elem <0:\n",
        "        final_pred.append(0.00001)\n",
        "      else:\n",
        "        final_pred.append(0.99999)\n",
        "      if over_values==True:\n",
        "        print(\"Wrong values\")\n",
        "        over_values=True\n",
        "    else:\n",
        "      final_pred.append(elem)\n",
        "  submission[key]=final_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best algorithm was  SVR  with training score  0.17820685056365027  for  question_asker_intent_understanding\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.31535430555543964  for  question_body_critical\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.173010261556178  for  question_conversational\n",
            "Best algorithm was  SVR  with training score  0.15461782568116567  for  question_interestingness_others\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.17427760463013173  for  question_interestingness_self\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.17097779252479164  for  question_multi_intent\n",
            "Best algorithm was  SVR  with training score  0.02123468530612179  for  question_not_really_a_question\n",
            "Best algorithm was  SVR  with training score  0.189370872956142  for  question_opinion_seeking\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.13173204525984542  for  question_fact_seeking\n",
            "Best algorithm was  SVR  with training score  0.3445606976176622  for  question_well_written\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.13358891474377782  for  question_type_entity\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.17786389871744684  for  question_type_choice\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.0871175540397091  for  question_type_compare\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.021428470284494176  for  question_type_consequence\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.14119664817129546  for  question_type_definition\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.31749256892420674  for  question_type_instructions\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.047936900377725765  for  question_type_procedure\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.19551050409860815  for  question_type_reason_explanation\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.06125104976672804  for  question_type_spelling\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.09983617591381345  for  answer_helpful\n",
            "Best algorithm was  SVR  with training score  0.3802725063012718  for  answer_level_of_information\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.2080850078070692  for  answer_type_instructions\n",
            "Best algorithm was  SGDRegressor  with training score  0.07976072077887435  for  answer_type_procedure\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.02618071811387546  for  answer_plausible\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.0725086951122146  for  answer_relevance\n",
            "Best algorithm was  SVR  with training score  0.22451322162639253  for  answer_satisfaction\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.3210259598405564  for  answer_type_reason_explanation\n",
            "Best algorithm was  SGDRegressor  with training score  0.0706833864209451  for  answer_well_written\n",
            "Best algorithm was  SVR  with training score  0.1963470173721226  for  question_expect_short_answer\n",
            "Best algorithm was  RandomForestRegressor  with training score  0.2000839924871087  for  question_has_commonly_accepted_answer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrfFTRukOqbT",
        "colab_type": "code",
        "trusted": true,
        "outputId": "cca8b885-5971-47e0-cc0a-e3ee487b59b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "submission=pd.read_csv('submission.csv')\n",
        "print(submission.shape)\n",
        "submission.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(476, 31)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_asker_intent_understanding</th>\n",
              "      <th>question_body_critical</th>\n",
              "      <th>question_conversational</th>\n",
              "      <th>question_expect_short_answer</th>\n",
              "      <th>question_fact_seeking</th>\n",
              "      <th>question_has_commonly_accepted_answer</th>\n",
              "      <th>question_interestingness_others</th>\n",
              "      <th>question_interestingness_self</th>\n",
              "      <th>question_multi_intent</th>\n",
              "      <th>question_not_really_a_question</th>\n",
              "      <th>question_opinion_seeking</th>\n",
              "      <th>question_type_choice</th>\n",
              "      <th>question_type_compare</th>\n",
              "      <th>question_type_consequence</th>\n",
              "      <th>question_type_definition</th>\n",
              "      <th>question_type_entity</th>\n",
              "      <th>question_type_instructions</th>\n",
              "      <th>question_type_procedure</th>\n",
              "      <th>question_type_reason_explanation</th>\n",
              "      <th>question_type_spelling</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "      <td>476.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5029.186975</td>\n",
              "      <td>0.889925</td>\n",
              "      <td>0.637974</td>\n",
              "      <td>0.222692</td>\n",
              "      <td>0.654009</td>\n",
              "      <td>0.617703</td>\n",
              "      <td>0.592979</td>\n",
              "      <td>0.663784</td>\n",
              "      <td>0.554919</td>\n",
              "      <td>0.344936</td>\n",
              "      <td>0.086207</td>\n",
              "      <td>0.445545</td>\n",
              "      <td>0.311339</td>\n",
              "      <td>0.084410</td>\n",
              "      <td>0.131033</td>\n",
              "      <td>0.048781</td>\n",
              "      <td>0.232930</td>\n",
              "      <td>0.423833</td>\n",
              "      <td>0.176563</td>\n",
              "      <td>0.537802</td>\n",
              "      <td>0.010362</td>\n",
              "      <td>0.848072</td>\n",
              "      <td>0.915616</td>\n",
              "      <td>0.659869</td>\n",
              "      <td>0.955936</td>\n",
              "      <td>0.956194</td>\n",
              "      <td>0.847155</td>\n",
              "      <td>0.392595</td>\n",
              "      <td>0.147765</td>\n",
              "      <td>0.570782</td>\n",
              "      <td>0.889990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2812.670060</td>\n",
              "      <td>0.021455</td>\n",
              "      <td>0.071698</td>\n",
              "      <td>0.095515</td>\n",
              "      <td>0.148076</td>\n",
              "      <td>0.105573</td>\n",
              "      <td>0.134567</td>\n",
              "      <td>0.069820</td>\n",
              "      <td>0.036705</td>\n",
              "      <td>0.060510</td>\n",
              "      <td>0.017961</td>\n",
              "      <td>0.150689</td>\n",
              "      <td>0.052995</td>\n",
              "      <td>0.041603</td>\n",
              "      <td>0.077127</td>\n",
              "      <td>0.054963</td>\n",
              "      <td>0.109210</td>\n",
              "      <td>0.081468</td>\n",
              "      <td>0.045131</td>\n",
              "      <td>0.108041</td>\n",
              "      <td>0.016549</td>\n",
              "      <td>0.103269</td>\n",
              "      <td>0.024530</td>\n",
              "      <td>0.075207</td>\n",
              "      <td>0.013787</td>\n",
              "      <td>0.022414</td>\n",
              "      <td>0.053690</td>\n",
              "      <td>0.087168</td>\n",
              "      <td>0.019733</td>\n",
              "      <td>0.130012</td>\n",
              "      <td>0.029270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.752310</td>\n",
              "      <td>0.487780</td>\n",
              "      <td>0.021630</td>\n",
              "      <td>0.276420</td>\n",
              "      <td>0.326870</td>\n",
              "      <td>0.333570</td>\n",
              "      <td>0.504870</td>\n",
              "      <td>0.478350</td>\n",
              "      <td>0.107720</td>\n",
              "      <td>0.004430</td>\n",
              "      <td>0.043710</td>\n",
              "      <td>0.185550</td>\n",
              "      <td>0.030460</td>\n",
              "      <td>0.006180</td>\n",
              "      <td>0.012370</td>\n",
              "      <td>0.041560</td>\n",
              "      <td>0.230470</td>\n",
              "      <td>0.083590</td>\n",
              "      <td>0.272160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.511030</td>\n",
              "      <td>0.817890</td>\n",
              "      <td>0.468170</td>\n",
              "      <td>0.875110</td>\n",
              "      <td>0.863210</td>\n",
              "      <td>0.633680</td>\n",
              "      <td>0.262610</td>\n",
              "      <td>0.081420</td>\n",
              "      <td>0.157280</td>\n",
              "      <td>0.789860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2572.000000</td>\n",
              "      <td>0.881305</td>\n",
              "      <td>0.577647</td>\n",
              "      <td>0.162670</td>\n",
              "      <td>0.549772</td>\n",
              "      <td>0.542155</td>\n",
              "      <td>0.485688</td>\n",
              "      <td>0.613645</td>\n",
              "      <td>0.527845</td>\n",
              "      <td>0.334218</td>\n",
              "      <td>0.079710</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.276520</td>\n",
              "      <td>0.068040</td>\n",
              "      <td>0.047555</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.146530</td>\n",
              "      <td>0.360877</td>\n",
              "      <td>0.156745</td>\n",
              "      <td>0.455815</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777197</td>\n",
              "      <td>0.902100</td>\n",
              "      <td>0.598080</td>\n",
              "      <td>0.951165</td>\n",
              "      <td>0.947730</td>\n",
              "      <td>0.817168</td>\n",
              "      <td>0.327952</td>\n",
              "      <td>0.135300</td>\n",
              "      <td>0.517860</td>\n",
              "      <td>0.871030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5093.000000</td>\n",
              "      <td>0.891835</td>\n",
              "      <td>0.639630</td>\n",
              "      <td>0.227645</td>\n",
              "      <td>0.659920</td>\n",
              "      <td>0.621900</td>\n",
              "      <td>0.572495</td>\n",
              "      <td>0.655935</td>\n",
              "      <td>0.553335</td>\n",
              "      <td>0.359055</td>\n",
              "      <td>0.090135</td>\n",
              "      <td>0.433565</td>\n",
              "      <td>0.303585</td>\n",
              "      <td>0.084575</td>\n",
              "      <td>0.158880</td>\n",
              "      <td>0.019340</td>\n",
              "      <td>0.218820</td>\n",
              "      <td>0.423570</td>\n",
              "      <td>0.175250</td>\n",
              "      <td>0.536465</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.856015</td>\n",
              "      <td>0.922410</td>\n",
              "      <td>0.652150</td>\n",
              "      <td>0.960125</td>\n",
              "      <td>0.960735</td>\n",
              "      <td>0.860595</td>\n",
              "      <td>0.366135</td>\n",
              "      <td>0.152525</td>\n",
              "      <td>0.624370</td>\n",
              "      <td>0.891435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7482.000000</td>\n",
              "      <td>0.901182</td>\n",
              "      <td>0.687057</td>\n",
              "      <td>0.290470</td>\n",
              "      <td>0.762750</td>\n",
              "      <td>0.703735</td>\n",
              "      <td>0.695915</td>\n",
              "      <td>0.704730</td>\n",
              "      <td>0.579620</td>\n",
              "      <td>0.380527</td>\n",
              "      <td>0.096685</td>\n",
              "      <td>0.543967</td>\n",
              "      <td>0.335090</td>\n",
              "      <td>0.096552</td>\n",
              "      <td>0.184880</td>\n",
              "      <td>0.079735</td>\n",
              "      <td>0.297937</td>\n",
              "      <td>0.487728</td>\n",
              "      <td>0.184262</td>\n",
              "      <td>0.638653</td>\n",
              "      <td>0.019420</td>\n",
              "      <td>0.928535</td>\n",
              "      <td>0.933593</td>\n",
              "      <td>0.721832</td>\n",
              "      <td>0.965923</td>\n",
              "      <td>0.973137</td>\n",
              "      <td>0.883918</td>\n",
              "      <td>0.434060</td>\n",
              "      <td>0.159832</td>\n",
              "      <td>0.663920</td>\n",
              "      <td>0.910827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9640.000000</td>\n",
              "      <td>0.970140</td>\n",
              "      <td>0.844350</td>\n",
              "      <td>0.486950</td>\n",
              "      <td>0.972210</td>\n",
              "      <td>0.851450</td>\n",
              "      <td>0.877540</td>\n",
              "      <td>0.887610</td>\n",
              "      <td>0.671700</td>\n",
              "      <td>0.458100</td>\n",
              "      <td>0.134890</td>\n",
              "      <td>0.937910</td>\n",
              "      <td>0.529870</td>\n",
              "      <td>0.749000</td>\n",
              "      <td>0.466340</td>\n",
              "      <td>0.465220</td>\n",
              "      <td>0.612720</td>\n",
              "      <td>0.659210</td>\n",
              "      <td>0.506060</td>\n",
              "      <td>0.727340</td>\n",
              "      <td>0.092420</td>\n",
              "      <td>0.999990</td>\n",
              "      <td>0.955640</td>\n",
              "      <td>0.840350</td>\n",
              "      <td>0.970340</td>\n",
              "      <td>0.981740</td>\n",
              "      <td>0.999990</td>\n",
              "      <td>0.691010</td>\n",
              "      <td>0.198960</td>\n",
              "      <td>0.731300</td>\n",
              "      <td>0.970680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             qa_id  ...  answer_well_written\n",
              "count   476.000000  ...           476.000000\n",
              "mean   5029.186975  ...             0.889990\n",
              "std    2812.670060  ...             0.029270\n",
              "min      39.000000  ...             0.789860\n",
              "25%    2572.000000  ...             0.871030\n",
              "50%    5093.000000  ...             0.891435\n",
              "75%    7482.000000  ...             0.910827\n",
              "max    9640.000000  ...             0.970680\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo3tgDU8s8Sp",
        "colab_type": "code",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "submission.to_csv ('submission.csv', index = None, header=True,float_format='%.5f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_v0ucL9dhvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}